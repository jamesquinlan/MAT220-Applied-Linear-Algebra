
\section*{Definitions, theorems, and examples}
\begin{enumerate}
\item  \textbf{Algebraic Rules}:  Let $A, B, C$ be matrices and $a, b \in \mathbb{R}$ .  The following are valid algebra rules:
\begin{enumerate}
	\item $A+B = B+A$
	\item $(A+B)+C = A+(B+C)$
	\item $(AB)C = A(BC)$
	\item $A(B+C) = AB + BC$
	
	\item $(A+B)C = AC + BC$
	\item $(ab)A = a(bA)$
	\item $ a (AB) = (aA)B = A(aB)$
	\item $(a+b)A = aA+bA$
	\item $a(A+B) = aA +aB$
\end{enumerate}




\begin{example} If $a = 2$, and 
$$ A = \begin{bmatrix}  1& 2& 1\\ 3 & 3 & 5 \\ 2  &  4  &  1 \end{bmatrix} \text{\;\;\;\; and \;\;\;\;} B = \begin{bmatrix}  1& 0& 2\\ 2 & 1 &  1 \\ 5  &  4  &  1 \end{bmatrix}$$ 
then
 \begin{align*}
  2(A+B)  &= 2 \left( \begin{bmatrix}  1& 2& 1\\ 3 & 3 & 5 \\ 2  &  4  &  1 \end{bmatrix}+  \begin{bmatrix}  1& 0& 2\\ 2 & 1 &  1 \\ 5  &  4  &  1 \end{bmatrix} \right) \\
  &= 2 \begin{bmatrix} 2 & 2  &3 \\ 5 & 4 & 6 \\ 7  &  8  &  2  \end{bmatrix}\\
  &= \begin{bmatrix} 4 & 4  &6 \\ 10 & 8 & 12 \\ 14  &  16  &  4  \end{bmatrix}
 \end{align*}
 
 On the other hand, 
  \begin{align*}
  2A+2B  &=  2 \begin{bmatrix}  1& 2& 1\\ 3 & 3 & 5 \\ 2  &  4  &  1 \end{bmatrix}+ 2 \begin{bmatrix}  1& 0& 2\\ 2 & 1 &  1 \\ 5  &  4  &  1 \end{bmatrix}  \\
  &=   \begin{bmatrix}  2& 4& 2\\ 6 & 6 & 10 \\ 4  &  8  &  2 \end{bmatrix}+  \begin{bmatrix}  2& 0& 4\\ 4 & 2 &  2 \\ 10  &  8  &  2 \end{bmatrix} \\
  &= \begin{bmatrix} 4 & 4  &6 \\ 10 & 8 & 12 \\ 14  &  16  &  4  \end{bmatrix}
 \end{align*}
\end{example}




% Example 
\begin{example} If
$$ A = \begin{bmatrix}  1& 2& 3 & 4\\ 5 & 6 & 7  & 8 \end{bmatrix} \text{\;\;\;\; and \;\;\;\;} B = \begin{bmatrix}  3& 1& 5 & 2\\ -1 & 2 & 4  & 1 \end{bmatrix}$$ 
then
 $$ A+B = \begin{bmatrix}  4& 3& 8 & 6\\ 4 & 8 & 11  & 9 \end{bmatrix} = B+A$$ 


\end{example}




NOTE:  In general $AB \ne BA$

\rule[0.01in]{\textwidth}{0.0025in}
% ---------------------------------------------------- % 

\item \textbf{Power of a matrix (notation)}:  Repeated multiplication of an $n \times n$ matrix $A$ with itself:
\[  A^k = \underbrace{AA \cdots A}_{\text{$k$ times}} \]


\begin{example} $A^3 = AAA$
\end{example}


\rule[0.01in]{\textwidth}{0.0025in}
% ---------------------------------------------------- % 



% IDENTITY MATRIX
\item \textbf{Identity matrix}:  A special matrix that acts like the identity element $1 \in \mathbb{R}$.  That is, the matrix $I$ such that $AI = A$ and $IA=A$ is called the identity matrix for any $n \times n$ matrix $A$.

\begin{definition}[Identity matrix]
The $n \times n$ \textbf{identity matrix} is $I = (\delta_{ij})$,  where

\[ 
 \delta_{ij} =  \begin{cases} 	1 & \text{ if \;} i = j\\
						0 & \text{ if \;} i \ne j
			\end{cases}
			\]
\end{definition}



\textbf{Alternative notation}:  The $n \times n$ identity matrix can be written using the row of columns notation, 
$$ I  = ({\bf e}_1 \;\; \;{\bf e}_2 \; \;\; {\bf e}_3 \; \;\; \cdots \; \;\; {\bf e}_n)$$
The $j$-th column of $I$ is $${\bf e}_j = \begin{bmatrix} 0 \\ \vdots \\ 1 \\ \vdots \\   0 \end{bmatrix}$$

\begin{example}
The $4 \times 4$ identity matrix is

\[ I  = \begin{bmatrix} 1 & 0 &  0 &   0  \\ 0 & 1 &  0 &   0  \\ 0 & 0 &  1 &   0  \\ 0 & 0 &  0 &  1  \end{bmatrix} \]
 \end{example}
 
 

\rule[0.01in]{\textwidth}{0.0025in}
% ---------------------------------------------------- % 








\item \textbf{Matrix Inversion}: Analogous to real numbers, we seek inverses in order to solve an equation.  In particular, to solve for ${\bf x}$ in equation $A {\bf x} = {\bf b}$, we need to multiply both sides by the inverse of $A$ (if it exists of course)

\begin{align*}
	A {\bf x} &= {\bf b} \\
	 A^{-1} A {\bf x} &= {\bf b} \\
	  {\bf x} &= A^{-1} {\bf b}
\end{align*}



\textbf{MATLAB commands}
\begin{verbatim}
>> inv(A); 		         % the inverse of A
>> x = A\b		          % use to solve equation Ax = b for x
\end{verbatim}
\vspace{0.2cm}


\begin{definition}
	An $n \times n$ matrix $A$ is \textbf{nonsingular} or \textbf{invertible} if there exists a matrix $B$ such that $AB = BA = I$.  The matrix $B$ is said to be a \textbf{multiplicative inverse} of $A$.
\end{definition}

\vspace{0.2cm}

\begin{definition}
	An $n \times n$ matrix $A$ is \textbf{singular} is it is not invertible (i.e., does not have a multiplicative inverse).  It is not nonsingular.
\end{definition}
\vspace{0.2cm}

NOTE: It only makes sense to talk about singular / nonsingular for square matrices.  

NOTE: nonsingular = good, singular = bad  (well, sort of)



\begin{example}
Find the inverse of $A$ given by
\[ A = \begin{bmatrix} 2 & 4 \\ 3 & 1  \end{bmatrix} \]
Augment $A$ with the identity matrix $I$, then perform elementary row operations to reduce $A$ to $I$, the inverse will be on the right.

\[  \begin{bmatrix}[cc|cc]  2 & 4  &  1  &  0 \\ 3 & 1 &  0  &  1  \end{bmatrix}    \to \begin{bmatrix}[cc|cc]  1& 0  &  -\frac{1}{10}  &  \frac{2}{5} \\ 0 & 1 &  \frac{3}{10}  &  \frac{1}{5}  \end{bmatrix}  \] 
\end{example}

\vspace{0.2cm}
\begin{theorem}
	If $A$ and $B$ are nonsingular $n \times n$ matrices, then $AB$ is nonsingular and $(AB)^{-1} = B^{-1}A^{-1}$.
	
	\proof It is easy to see that $I = A(BB^{-1})A^{-1} = (AB)(B^{-1}A^{-1})$.  Similarly,  $I = B^{-1}(A^{-1}A)B =  (B^{-1}A^{-1})(AB)$.  Therefore, $(AB)^{-1} = B^{-1}A^{-1}$.  
\end{theorem}


\vspace{0.2cm}

\textbf{How to tell if a matrix is nonsingular in MATLAB}
 \begin{verbatim}
% A is invertible if: 
>> inv(A); 		         % exists
>> rank(A)		          % = n
>> rref(A)			          % = I 
\end{verbatim}
\vspace{0.2cm}




\begin{definition}
	An $n \times n$ matrix $A$ is an \textbf{involution} matrix if $A^2 = I$.
\end{definition}


\vspace{0.2cm}
\begin{example}
	Show that $H = I - 2 {\bf u}{\bf u}^T$ is an involution when ${\bf u}$ is a unit vector.  
	
	\proof 
	\begin{align*}
		H^2 &= (I - 2 {\bf u}{\bf u}^T)^2\\
			&= (I - 2 {\bf u}{\bf u}^T)(I - 2 {\bf u}{\bf u}^T) \\
			&= I -4{\bf u}{\bf u}^T + 4({\bf u}{\bf u}^T)^2 \\
			&=I - 4{\bf u}{\bf u}^T + 4({\bf u}{\bf u}^T)({\bf u}{\bf u}^T) \\
			&= I- 4{\bf u}{\bf u}^T + 4{\bf u}({\bf u}^T {\bf u}){\bf u}^T \\
			&= I - 4{\bf u}{\bf u}^T + 4{\bf u}{\bf u}^T   \hspace{1.0in} \text{ (i.e., \; } {\bf u}^T {\bf u} = 1)\\
			&= I
	\end{align*}
\end{example}
\rule[0.01in]{\textwidth}{0.0025in}
% ---------------------------------------------------- % 















% TRANSPOSE 
\item The \textbf{Transpose} of an $m \times n$ matrix $A$ is the $n \times m$ matrix $B$ defined by
\[ b_{ij} = a_{ji} \]

The rows of $A$ are the columns of $B$.  The transpose is denoted by $A^T$.
Therefore
 $$A = \begin{bmatrix} \vec{{\bf a_1}}\\ \vec{{\bf a_2}} \\ \vec{{\bf a_3}} \\ \vdots \\ \vec{{\bf a_m}} \end{bmatrix}     \hspace{0.5cm} \text{ then } \hspace{0.5cm}      A^T=({\bf a_1} \;\; \;{\bf a_2} \; \;\; {\bf a_3} \; \;\; \cdots \; \;\; {\bf a_n})$$

\textbf{MATLAB command} - use single quote at end of matrix
\begin{verbatim}
>> A'
\end{verbatim}

\begin{example}
If  \[ A = \begin{bmatrix} 1 & 2 &3 \\ 4 & 5 & 6 \end{bmatrix} \]
then
\[ A^T = \begin{bmatrix} 1 & 4  \\ 2 & 5 \\ 3 & 6 \end{bmatrix} \]
 \end{example}
 
 
 
 \item \textbf{Symmetric} - A square matrix ($n \times n$) is symmetric if $A^T = A$.
 
 
 
 \item \textbf{Algebraic rules for Transposes}
 \begin{enumerate}
 	\item $(A^{T})^T = A$
	\item $(\alpha A)^T = \alpha A^{T}$
	\item $(A+B)^T = A^{T}+ B^{T}$
	\item $ (AB)^T = B^T A^{T} $
 \end{enumerate}

\rule[0.01in]{\textwidth}{0.0025in}
% ---------------------------------------------------- % 



\end{enumerate}









\section*{Summary}
Matrices are analogous to real numbers in the sense of they are the objects of an algebra (a nonempty set with arithmetic operations of $+$ and $\times$ where certain properties hold, e.g., distributive property $a\times (b+c) = a\times b+a\times c$).  Unfortunately, matrices differ from real numbers in at least two significant ways: 
\begin{enumerate}
	\item Commutative property fails, $AB \ne BA$ in general
	\item Not every ($n \times n$) matrix has an inverse.  This makes it problematic to uniquely solve a system of equations  
\end{enumerate}
The set of $n \times n$ matrices over the real numbers is a noncommutative ring, whereas the real numbers form a field.  


In this section we 
\begin{enumerate}
	\item Listed the Algebraic properties of matrices (e.g., $A+B = B+A$ and $A^2 = AA$)
	\item Discussed the importance and meaning of an inverse matrix and how it is related to the identity matrix.
	\item Defined nonsingular and consequences based on algebraic properties (e.g., the product of two nonsingular matrices is nonsingular)  
	\item Listed the algebraic rules for transposes
	
\end{enumerate}
 



\section*{Next time...}
Section 1.5 - Elementary matrices

